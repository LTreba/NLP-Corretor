{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0FaaM7HXD6E"
      },
      "source": [
        "**Abrindo corpus**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybbjPLhpRBwU",
        "outputId": "a8349588-e6e0-48f5-9cc2-b587f64796f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "imagem \n",
            "\n",
            "Temos a seguinte classe que representa um usuário no nosso sistema:\n",
            "\n",
            "java\n",
            "\n",
            "Para salvar um novo usuário, várias validações são feitas, como por exemplo: Ver se o nome só contém letras, [**o CPF só números**] e ver se o usuário possui no mínimo 18 anos. Veja o método que faz essa validação:\n",
            "\n",
            "java \n",
            "\n",
            "Suponha agora que eu tenha outra classe, a classe `Produto`, que contém um atributo nome e eu quero fazer a mesma validação que fiz para o nome do usuário: Ver se só contém letras. E aí? Vou\n"
          ]
        }
      ],
      "source": [
        "with open(\"\\Corpus\\artigos.txt\",\"r\") as f:\n",
        "  artigos = f.read()\n",
        "\n",
        "print(artigos[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eK9qp_BYSy0S",
        "outputId": "324ef5b6-3d53-431e-b44d-d9ddc25ef6a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2605046"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(artigos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8faHMnyXHm_"
      },
      "source": [
        "**Realizando processo de tokenização de palavras**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMV5UtoBS5mF",
        "outputId": "4a9d8e9d-012e-4867-d084-eddd7545949e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "tokens = nltk.tokenize.word_tokenize(artigos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "9-RdZmjcV5bn"
      },
      "outputs": [],
      "source": [
        "def separa_palavras(lista_tokens):\n",
        "    lista_palavras = []\n",
        "    for token in lista_tokens:\n",
        "      if(token.isalpha()):\n",
        "        lista_palavras.append(token)\n",
        "    return lista_palavras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xadyLLJWh7a",
        "outputId": "55f7a104-8007-44ce-c57d-9c07aa70f91b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "O número de palavras é 403104\n"
          ]
        }
      ],
      "source": [
        "\n",
        "lista_palavras = separa_palavras(tokens)\n",
        "print(f\"O número de palavras é {len(lista_palavras)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "568mJkuoXN69"
      },
      "source": [
        "**Retirando recorrências**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEtmC_-CXlPl",
        "outputId": "9a9b4d8c-e03c-4db6-e5f1-8200508aae4e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "18465"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def normalizacao(lista_palavras):\n",
        "  lista_normalizada = list()\n",
        "  for palavra in lista_palavras:\n",
        "    lista_normalizada.append(palavra.lower())\n",
        "  return(lista_normalizada)\n",
        "\n",
        "lista_normalizada = normalizacao(lista_palavras)\n",
        "\n",
        "len(set(lista_normalizada))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "198cJRcirFmW"
      },
      "source": [
        "**Avaliando Corretor**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "okMx5w02nAnD"
      },
      "outputs": [],
      "source": [
        "\n",
        "def corretor(palavra):\n",
        "    palavras_geradas = gerador_palavras(palavra)\n",
        "    palavra_correta = max(palavras_geradas, key=probabilidade)\n",
        "    return palavra_correta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzWEAs6WnyYT",
        "outputId": "aee97348-8e3a-4d5e-d4ed-e8ca27828e7b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('de', 15502),\n",
              " ('o', 14056),\n",
              " ('que', 12230),\n",
              " ('a', 11099),\n",
              " ('e', 10501),\n",
              " ('para', 7710),\n",
              " ('um', 6368),\n",
              " ('é', 5899),\n",
              " ('uma', 5220),\n",
              " ('do', 5124)]"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "frequencia = nltk.FreqDist(lista_normalizada)\n",
        "total_palavras = len(lista_normalizada)\n",
        "frequencia.most_common(10)\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "whBWUvJipRZQ"
      },
      "outputs": [],
      "source": [
        "def probabilidade(palavra_gerada):\n",
        "    return frequencia[palavra_gerada]/total_palavras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "U3DYmR8UrIuv"
      },
      "outputs": [],
      "source": [
        "def cria_dados_teste(nome_arquivo):\n",
        "  lista_palavra_teste = []\n",
        "  f = open(\"nome_arquivo\",\"r\")\n",
        "  for linha in f:\n",
        "    correta, errada = linha.split()\n",
        "    lista_palavra_teste.append((correta,errada))\n",
        "  f.close()\n",
        "  return(lista_palavra_teste)\n",
        "\n",
        "def avaliador(testes, vocabulario):\n",
        "    numero_palavras = len(testes)\n",
        "    acertou = 0\n",
        "    desconhecida = 0\n",
        "    for correta, errada in testes:\n",
        "        palavra_corrigida = corretor(errada)\n",
        "        desconhecida += (correta not in vocabulario)\n",
        "        if palavra_corrigida == correta:\n",
        "            acertou += 1\n",
        "    taxa_acerto = round(acertou*100/numero_palavras, 2)\n",
        "    taxa_desconhecida = round(desconhecida*100/numero_palavras, 2)\n",
        "    print(f\"{taxa_acerto}% de {numero_palavras} palavras, desconhecidas {taxa_desconhecida}%\")\n",
        "\n",
        "vocabulario = set(lista_normalizada)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaJWoOh30Qke"
      },
      "source": [
        "**Realizando Operações do Corretor**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDvS4wfzyEIQ",
        "outputId": "694a9399-77d5-4b78-8e36-174979f98fe0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['algóica', 'blgóica', 'clgóica', 'dlgóica', 'elgóica', 'flgóica', 'glgóica', 'hlgóica', 'ilgóica', 'jlgóica', 'klgóica', 'llgóica', 'mlgóica', 'nlgóica', 'olgóica', 'plgóica', 'qlgóica', 'rlgóica', 'slgóica', 'tlgóica', 'ulgóica', 'vlgóica', 'wlgóica', 'xlgóica', 'ylgóica', 'zlgóica', 'àlgóica', 'álgóica', 'âlgóica', 'ãlgóica', 'èlgóica', 'élgóica', 'êlgóica', 'ìlgóica', 'ílgóica', 'îlgóica', 'òlgóica', 'ólgóica', 'ôlgóica', 'õlgóica', 'ùlgóica', 'úlgóica', 'ûlgóica', 'çlgóica', 'lagóica', 'lbgóica', 'lcgóica', 'ldgóica', 'legóica', 'lfgóica', 'lggóica', 'lhgóica', 'ligóica', 'ljgóica', 'lkgóica', 'llgóica', 'lmgóica', 'lngóica', 'logóica', 'lpgóica', 'lqgóica', 'lrgóica', 'lsgóica', 'ltgóica', 'lugóica', 'lvgóica', 'lwgóica', 'lxgóica', 'lygóica', 'lzgóica', 'làgóica', 'lágóica', 'lâgóica', 'lãgóica', 'lègóica', 'légóica', 'lêgóica', 'lìgóica', 'lígóica', 'lîgóica', 'lògóica', 'lógóica', 'lôgóica', 'lõgóica', 'lùgóica', 'lúgóica', 'lûgóica', 'lçgóica', 'lgaóica', 'lgbóica', 'lgcóica', 'lgdóica', 'lgeóica', 'lgfóica', 'lggóica', 'lghóica', 'lgióica', 'lgjóica', 'lgkóica', 'lglóica', 'lgmóica', 'lgnóica', 'lgoóica', 'lgpóica', 'lgqóica', 'lgróica', 'lgsóica', 'lgtóica', 'lguóica', 'lgvóica', 'lgwóica', 'lgxóica', 'lgyóica', 'lgzóica', 'lgàóica', 'lgáóica', 'lgâóica', 'lgãóica', 'lgèóica', 'lgéóica', 'lgêóica', 'lgìóica', 'lgíóica', 'lgîóica', 'lgòóica', 'lgóóica', 'lgôóica', 'lgõóica', 'lgùóica', 'lgúóica', 'lgûóica', 'lgçóica', 'lgóaica', 'lgóbica', 'lgócica', 'lgódica', 'lgóeica', 'lgófica', 'lgógica', 'lgóhica', 'lgóiica', 'lgójica', 'lgókica', 'lgólica', 'lgómica', 'lgónica', 'lgóoica', 'lgópica', 'lgóqica', 'lgórica', 'lgósica', 'lgótica', 'lgóuica', 'lgóvica', 'lgówica', 'lgóxica', 'lgóyica', 'lgózica', 'lgóàica', 'lgóáica', 'lgóâica', 'lgóãica', 'lgóèica', 'lgóéica', 'lgóêica', 'lgóìica', 'lgóíica', 'lgóîica', 'lgóòica', 'lgóóica', 'lgóôica', 'lgóõica', 'lgóùica', 'lgóúica', 'lgóûica', 'lgóçica', 'lgóiaca', 'lgóibca', 'lgóicca', 'lgóidca', 'lgóieca', 'lgóifca', 'lgóigca', 'lgóihca', 'lgóiica', 'lgóijca', 'lgóikca', 'lgóilca', 'lgóimca', 'lgóinca', 'lgóioca', 'lgóipca', 'lgóiqca', 'lgóirca', 'lgóisca', 'lgóitca', 'lgóiuca', 'lgóivca', 'lgóiwca', 'lgóixca', 'lgóiyca', 'lgóizca', 'lgóiàca', 'lgóiáca', 'lgóiâca', 'lgóiãca', 'lgóièca', 'lgóiéca', 'lgóiêca', 'lgóiìca', 'lgóiíca', 'lgóiîca', 'lgóiòca', 'lgóióca', 'lgóiôca', 'lgóiõca', 'lgóiùca', 'lgóiúca', 'lgóiûca', 'lgóiçca', 'lgóicaa', 'lgóicba', 'lgóicca', 'lgóicda', 'lgóicea', 'lgóicfa', 'lgóicga', 'lgóicha', 'lgóicia', 'lgóicja', 'lgóicka', 'lgóicla', 'lgóicma', 'lgóicna', 'lgóicoa', 'lgóicpa', 'lgóicqa', 'lgóicra', 'lgóicsa', 'lgóicta', 'lgóicua', 'lgóicva', 'lgóicwa', 'lgóicxa', 'lgóicya', 'lgóicza', 'lgóicàa', 'lgóicáa', 'lgóicâa', 'lgóicãa', 'lgóicèa', 'lgóicéa', 'lgóicêa', 'lgóicìa', 'lgóicía', 'lgóicîa', 'lgóicòa', 'lgóicóa', 'lgóicôa', 'lgóicõa', 'lgóicùa', 'lgóicúa', 'lgóicûa', 'lgóicça', 'lgóicaa', 'lgóicab', 'lgóicac', 'lgóicad', 'lgóicae', 'lgóicaf', 'lgóicag', 'lgóicah', 'lgóicai', 'lgóicaj', 'lgóicak', 'lgóical', 'lgóicam', 'lgóican', 'lgóicao', 'lgóicap', 'lgóicaq', 'lgóicar', 'lgóicas', 'lgóicat', 'lgóicau', 'lgóicav', 'lgóicaw', 'lgóicax', 'lgóicay', 'lgóicaz', 'lgóicaà', 'lgóicaá', 'lgóicaâ', 'lgóicaã', 'lgóicaè', 'lgóicaé', 'lgóicaê', 'lgóicaì', 'lgóicaí', 'lgóicaî', 'lgóicaò', 'lgóicaó', 'lgóicaô', 'lgóicaõ', 'lgóicaù', 'lgóicaú', 'lgóicaû', 'lgóicaç', 'góica', 'lóica', 'lgica', 'lgóca', 'lgóia', 'lgóic', 'lgóica', 'agóica', 'bgóica', 'cgóica', 'dgóica', 'egóica', 'fgóica', 'ggóica', 'hgóica', 'igóica', 'jgóica', 'kgóica', 'lgóica', 'mgóica', 'ngóica', 'ogóica', 'pgóica', 'qgóica', 'rgóica', 'sgóica', 'tgóica', 'ugóica', 'vgóica', 'wgóica', 'xgóica', 'ygóica', 'zgóica', 'ágóica', 'àgóica', 'ãgóica', 'âgóica', 'égóica', 'ègóica', 'êgóica', 'ígóica', 'ìgóica', 'ógóica', 'ògóica', 'õgóica', 'ôgóica', 'úgóica', 'ùgóica', 'ûgóica', 'çgóica', 'laóica', 'lbóica', 'lcóica', 'ldóica', 'leóica', 'lfóica', 'lgóica', 'lhóica', 'lióica', 'ljóica', 'lkóica', 'llóica', 'lmóica', 'lnóica', 'loóica', 'lpóica', 'lqóica', 'lróica', 'lsóica', 'ltóica', 'luóica', 'lvóica', 'lwóica', 'lxóica', 'lyóica', 'lzóica', 'láóica', 'làóica', 'lãóica', 'lâóica', 'léóica', 'lèóica', 'lêóica', 'líóica', 'lìóica', 'lóóica', 'lòóica', 'lõóica', 'lôóica', 'lúóica', 'lùóica', 'lûóica', 'lçóica', 'lgaica', 'lgbica', 'lgcica', 'lgdica', 'lgeica', 'lgfica', 'lggica', 'lghica', 'lgiica', 'lgjica', 'lgkica', 'lglica', 'lgmica', 'lgnica', 'lgoica', 'lgpica', 'lgqica', 'lgrica', 'lgsica', 'lgtica', 'lguica', 'lgvica', 'lgwica', 'lgxica', 'lgyica', 'lgzica', 'lgáica', 'lgàica', 'lgãica', 'lgâica', 'lgéica', 'lgèica', 'lgêica', 'lgíica', 'lgìica', 'lgóica', 'lgòica', 'lgõica', 'lgôica', 'lgúica', 'lgùica', 'lgûica', 'lgçica', 'lgóaca', 'lgóbca', 'lgócca', 'lgódca', 'lgóeca', 'lgófca', 'lgógca', 'lgóhca', 'lgóica', 'lgójca', 'lgókca', 'lgólca', 'lgómca', 'lgónca', 'lgóoca', 'lgópca', 'lgóqca', 'lgórca', 'lgósca', 'lgótca', 'lgóuca', 'lgóvca', 'lgówca', 'lgóxca', 'lgóyca', 'lgózca', 'lgóáca', 'lgóàca', 'lgóãca', 'lgóâca', 'lgóéca', 'lgóèca', 'lgóêca', 'lgóíca', 'lgóìca', 'lgóóca', 'lgóòca', 'lgóõca', 'lgóôca', 'lgóúca', 'lgóùca', 'lgóûca', 'lgóçca', 'lgóiaa', 'lgóiba', 'lgóica', 'lgóida', 'lgóiea', 'lgóifa', 'lgóiga', 'lgóiha', 'lgóiia', 'lgóija', 'lgóika', 'lgóila', 'lgóima', 'lgóina', 'lgóioa', 'lgóipa', 'lgóiqa', 'lgóira', 'lgóisa', 'lgóita', 'lgóiua', 'lgóiva', 'lgóiwa', 'lgóixa', 'lgóiya', 'lgóiza', 'lgóiáa', 'lgóiàa', 'lgóiãa', 'lgóiâa', 'lgóiéa', 'lgóièa', 'lgóiêa', 'lgóiía', 'lgóiìa', 'lgóióa', 'lgóiòa', 'lgóiõa', 'lgóiôa', 'lgóiúa', 'lgóiùa', 'lgóiûa', 'lgóiça', 'lgóica', 'lgóicb', 'lgóicc', 'lgóicd', 'lgóice', 'lgóicf', 'lgóicg', 'lgóich', 'lgóici', 'lgóicj', 'lgóick', 'lgóicl', 'lgóicm', 'lgóicn', 'lgóico', 'lgóicp', 'lgóicq', 'lgóicr', 'lgóics', 'lgóict', 'lgóicu', 'lgóicv', 'lgóicw', 'lgóicx', 'lgóicy', 'lgóicz', 'lgóicá', 'lgóicà', 'lgóicã', 'lgóicâ', 'lgóicé', 'lgóicè', 'lgóicê', 'lgóicí', 'lgóicì', 'lgóicó', 'lgóicò', 'lgóicõ', 'lgóicô', 'lgóicú', 'lgóicù', 'lgóicû', 'lgóicç', 'lgóicaa', 'lgóicab', 'lgóicac', 'lgóicad', 'lgóicae', 'lgóicaf', 'lgóicag', 'lgóicah', 'lgóicai', 'lgóicaj', 'lgóicak', 'lgóical', 'lgóicam', 'lgóican', 'lgóicao', 'lgóicap', 'lgóicaq', 'lgóicar', 'lgóicas', 'lgóicat', 'lgóicau', 'lgóicav', 'lgóicaw', 'lgóicax', 'lgóicay', 'lgóicaz', 'lgóicaá', 'lgóicaà', 'lgóicaã', 'lgóicaâ', 'lgóicaé', 'lgóicaè', 'lgóicaê', 'lgóicaí', 'lgóicaì', 'lgóicaó', 'lgóicaò', 'lgóicaõ', 'lgóicaô', 'lgóicaú', 'lgóicaù', 'lgóicaû', 'lgóicaç', 'glóica', 'lógica', 'lgióca', 'lgócia', 'lgóiac']\n"
          ]
        }
      ],
      "source": [
        "def insere_letras(fatias):\n",
        "    novas_palavras = []\n",
        "    letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
        "    for E, D in fatias:\n",
        "        for letra in letras:\n",
        "            novas_palavras.append(E + letra + D)\n",
        "    return novas_palavras\n",
        "\n",
        "def deletando_caracteres(fatias):\n",
        "    novas_palavras = []\n",
        "    for E, D in fatias:\n",
        "        novas_palavras.append(E + D[1:])\n",
        "    return novas_palavras\n",
        "\n",
        "def troca_letra(fatias):\n",
        "    novas_palavras = []\n",
        "    letras = 'abcdefghijklmnopqrstuvwxyzáàãâéèêíìóòõôúùûç'\n",
        "    for E, D in fatias:\n",
        "        for letra in letras:\n",
        "            novas_palavras.append(E + letra + D[1:])\n",
        "    return novas_palavras\n",
        "\n",
        "def inverte_letra(fatias):\n",
        "    novas_palavras = []\n",
        "    for E, D in fatias:\n",
        "        if len(D) > 1:\n",
        "            novas_palavras.append(E + D[1] + D[0] + D[2:])\n",
        "    return novas_palavras\n",
        "\n",
        "def gerador_palavras(palavra):\n",
        "    fatias = []\n",
        "    for i in range(len(palavra)+1):\n",
        "        fatias.append((palavra[:i],palavra[i:]))\n",
        "    palavras_geradas = insere_letras(fatias)\n",
        "    palavras_geradas += deletando_caracteres(fatias)\n",
        "    palavras_geradas += troca_letra(fatias)\n",
        "    palavras_geradas += inverte_letra(fatias)\n",
        "    return palavras_geradas\n",
        "\n",
        "palavra_exemplo = \"lgóica\"\n",
        "palavras_geradas = gerador_palavras(palavra_exemplo)\n",
        "print(palavras_geradas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2FJO_734-IO"
      },
      "source": [
        "**Melhorando o gerador de palavras e o corretor**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enQvUHTy5AqU",
        "outputId": "ef535996-c406-4987-cf0d-fe8c4d998c7e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "676760"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "palavra = \"lóiigica\"\n",
        "\n",
        "def gerador_turbinado(palavras_geradas):\n",
        "    novas_palavras = []\n",
        "    for palavra in palavras_geradas:\n",
        "        novas_palavras += gerador_palavras(palavra)\n",
        "    return novas_palavras\n",
        "\n",
        "palavras_g = gerador_turbinado(gerador_palavras(palavra))\n",
        "\"lógica\" in palavras_g\n",
        "len(palavras_g)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "AUNEQeI37b-d",
        "outputId": "3234a46d-1527-43d7-d663-f31a64953bb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'lógica'"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def novo_corretor(palavra):\n",
        "    palavras_geradas = gerador_palavras(palavra)\n",
        "    palavras_turbinado = gerador_turbinado(palavras_geradas)\n",
        "    todas_palavras = set(palavras_geradas + palavras_turbinado)\n",
        "    candidatos = [palavra]\n",
        "    for palavra in todas_palavras:\n",
        "        if palavra in vocabulario:\n",
        "            candidatos.append(palavra)\n",
        "    palavra_correta = max(candidatos, key=probabilidade)\n",
        "    return palavra_correta\n",
        "\n",
        "novo_corretor(palavra)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
